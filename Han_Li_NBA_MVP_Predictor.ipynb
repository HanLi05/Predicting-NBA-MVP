{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanLi05/Predicting-NBA-MVP/blob/main/Han_Li_NBA_MVP_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount to google drive, import libraries"
      ],
      "metadata": {
        "id": "FXRKWfFjGGPp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPimIwYbvO2v",
        "outputId": "e821db39-b587-4d30-f095-3a1b5220b41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.metrics import r2_score\n",
        "import os"
      ],
      "metadata": {
        "id": "ibbyUgasGOLO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrape basketball reference for team stats from 2001-2023"
      ],
      "metadata": {
        "id": "0mxgC6wvUD6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "# loop over every season from 2000-01 to 2022-23\n",
        "for year in range(2001, 2023):\n",
        "  # create url\n",
        "  url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
        "\n",
        "  # send HTTP request and parse HTML content\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "  # loop over the two tables on the webpage\n",
        "  for num in range(2):\n",
        "    # extract table headers\n",
        "    table = soup.find_all('table')[num]\n",
        "    headers = table.find_all('thead')[0].find_all('th')\n",
        "    header_names = ['Year'] + [header.get_text() for header in headers[0:-1]] + ['League']\n",
        "\n",
        "    # extract table rows\n",
        "    rows = table.find_all('tbody')[0].find_all('tr')\n",
        "    for row in rows:\n",
        "      # skip rows with no data\n",
        "      if len(row.find_all('td')) == 0:\n",
        "        continue\n",
        "      # extract data from cells in row\n",
        "      row_data = [year] + [cell.get_text() for cell in row.find_all('td')] + [row.find_all('td')[-1].get_text()] + [cell.get_text() for cell in row.find_all('th')] + [row.find_all('th')[-1].get_text()]\n",
        "      data.append(row_data)\n",
        "\n",
        "  # add data to dataframe, drop unnecessary columns\n",
        "  team_stats_df = pd.DataFrame(data, columns=['Year', 'W', 'L', 'W/L%', 'GB', 'PS/G', 'PA/G', 'League', '?', 'Team Name', 'yfv'])\n",
        "  team_stats_df = team_stats_df.drop(columns=['League', '?', 'yfv'])\n",
        "\n",
        "# save to csv\n",
        "team_stats_df.to_csv('team_stats.csv', index=False)"
      ],
      "metadata": {
        "id": "l0v23Q8TQTDc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read data from google drive datasets (player stats, MVP voting)\n"
      ],
      "metadata": {
        "id": "ugklRwoyZutd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read data from all_seasons file - player statistics for each year\n",
        "zf = zipfile.ZipFile('/content/drive/MyDrive/ML/archive (1).zip')\n",
        "adv_df = pd.read_csv(zf.open('all_seasons.csv'))\n",
        "\n",
        "# read data from folder - contains mvp voting results for each year in separate csv file\n",
        "folder_path = '/content/drive/MyDrive/ML/folder'\n",
        "\n",
        "file_list = os.listdir(folder_path)\n",
        "df_list = []\n",
        "\n",
        "# for every file in folder, append it to a dataframe df\n",
        "for file_name in file_list:\n",
        "  df = pd.read_csv(os.path.join(folder_path, file_name))\n",
        "  df_list.append(df)\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# fix columns\n",
        "df.columns = df.iloc[0]\n",
        "df = df.drop(df.index[0])\n",
        "\n",
        "# files were ordered from most recently to least recent\n",
        "# add a season value to each row when the rank resets to 1 (indicates start of new season)\n",
        "num = 23\n",
        "df['Season'] = 0\n",
        "for index, row in df.iterrows():\n",
        "    if row['Rank'] == '1':\n",
        "        num-=1\n",
        "    # account for different logic during 2000-2009 versus 2010 onwards\n",
        "    if num > 10:\n",
        "      df.at[index, 'Season'] = '20'+str(num-1)+'-'+str(num)\n",
        "    else:\n",
        "      df.at[index, 'Season'] = '200'+str(num-1)+'-0'+str(num)\n",
        "\n",
        "# drop rows that are not useful\n",
        "for index, row in df.iterrows():\n",
        "  if row['Tm'] == 'TOT':\n",
        "    df = df.drop(index)\n",
        "  if row['Rank'] == 'Rank':\n",
        "    df = df.drop(index)"
      ],
      "metadata": {
        "id": "gG1sqIwxGmS8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary to convert datasets which use\n",
        "nba_teams = {\n",
        "    \"ATL\": \"Atlanta Hawks\",\n",
        "    \"BOS\": \"Boston Celtics\",\n",
        "    \"BRK\": \"Brooklyn Nets\",\n",
        "    \"CHA\": \"Charlotte Hornets\",\n",
        "    \"CHI\": \"Chicago Bulls\",\n",
        "    \"CLE\": \"Cleveland Cavaliers\",\n",
        "    \"DAL\": \"Dallas Mavericks\",\n",
        "    \"DEN\": \"Denver Nuggets\",\n",
        "    \"DET\": \"Detroit Pistons\",\n",
        "    \"GSW\": \"Golden State Warriors\",\n",
        "    \"HOU\": \"Houston Rockets\",\n",
        "    \"IND\": \"Indiana Pacers\",\n",
        "    \"LAC\": \"Los Angeles Clippers\",\n",
        "    \"LAL\": \"Los Angeles Lakers\",\n",
        "    \"MEM\": \"Memphis Grizzlies\",\n",
        "    \"MIA\": \"Miami Heat\",\n",
        "    \"MIL\": \"Milwaukee Bucks\",\n",
        "    \"MIN\": \"Minnesota Timberwolves\",\n",
        "    \"NOP\": \"New Orleans Pelicans\",\n",
        "    \"NYK\": \"New York Knicks\",\n",
        "    \"OKC\": \"Oklahoma City Thunder\",\n",
        "    \"ORL\": \"Orlando Magic\",\n",
        "    \"PHI\": \"Philadelphia 76ers\",\n",
        "    \"PHO\": \"Phoenix Suns\",\n",
        "    \"POR\": \"Portland Trail Blazers\",\n",
        "    \"SAC\": \"Sacramento Kings\",\n",
        "    \"SAS\": \"San Antonio Spurs\",\n",
        "    \"TOR\": \"Toronto Raptors\",\n",
        "    \"UTA\": \"Utah Jazz\",\n",
        "    \"WAS\": \"Washington Wizards\"\n",
        "}\n",
        "\n",
        "# team_stats_df = pd.read_csv('team_stats.csv')\n",
        "df1 = adv_df.drop(adv_df.columns[0], axis=1)\n",
        "\n",
        "# remove *'s in the Team Name column for team_stats_df\n",
        "for i in range(len(team_stats_df)):\n",
        "    team_stats_df.loc[i, 'Team Name'] = team_stats_df.loc[i, 'Team Name'].replace('*', '')\n",
        "\n",
        "# map team abbreviations in df to their full names\n",
        "df['Tm'] = df['Tm'].map(nba_teams)\n",
        "df = df.dropna()\n",
        "\n",
        "# construct 'Yr' from 'Season' so dataframes can merge on years (eg: 'Yr' = 2000, 'Season' = 2000-01)\n",
        "df['Yr'] = df['Season'].str[:2] + df['Season'].str[-2:]\n",
        "team_stats_df['Year'] = team_stats_df['Year'].astype(str)\n",
        "\n",
        "# merge to get combined df with team that the mvp candidates played on\n",
        "merged_df = pd.merge(df, team_stats_df, left_on=['Tm', 'Yr'], right_on=['Team Name', 'Year'])\n",
        "# extract the W/L% of each of the mvp candidates\n",
        "df['Wins'] = merged_df['W/L%']\n",
        "df = df.drop(columns = ['Yr'])\n",
        "\n",
        "# merge to get combined df with stats of mvp candidates\n",
        "df['Net Rating'] = 0\n",
        "df['TS%'] = 0\n",
        "df['USG%'] = 0\n",
        "merged_df = pd.merge(df, adv_df, left_on=['Player', 'Season'], right_on=['player_name', 'season'])\n",
        "# extract the net rating, true shooting percentages, and usage percentages\n",
        "# these statistics are more indicative of one's value, and is some of what I used for analysis\n",
        "df['Net Rating'] = merged_df['net_rating']\n",
        "df['TS%'] = merged_df['ts_pct']\n",
        "df['USG%'] = merged_df['usg_pct']\n",
        "\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtaseM0yQlb4",
        "outputId": "78931f19-734c-4cce-c35d-91122e999d25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-21e5da7a7687>:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Yr'] = df['Season'].str[:2] + df['Season'].str[-2:]\n",
            "<ipython-input-5-21e5da7a7687>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Wins'] = merged_df['W/L%']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select features (X) and target variable (y)\n",
        "# features include points, win shares, field goal %, their plus/minus rating, true shooting %, usage %, and team wins\n",
        "X = df[['PTS', 'WS', 'FG%', 'Net Rating', 'TS%', 'USG%', 'Wins']]\n",
        "y = df['Share']\n",
        "\n",
        "# split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=28)\n",
        "\n",
        "# create, train linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# performance of linear regression model on training and testing sets\n",
        "train_score = model.score(X_train, y_train)\n",
        "test_score = model.score(X_test, y_test)\n",
        "\n",
        "# R-squared scores - how well variance in target variable is explained by features of regression model\n",
        "print(\"Train R2:\", train_score)\n",
        "print(\"Test R2:\", test_score)\n",
        "\n",
        "# perform lasso regression with different alphas\n",
        "# penalize less relevant features, favors those with stronger relationship, prevents overfitting\n",
        "# different alphas dictate how much to penalize weaker features\n",
        "alphas = [0, 0.0001, 0.1]\n",
        "for alpha in alphas:\n",
        "  print()\n",
        "  # create and train lasso model\n",
        "  lasso = Lasso(alpha=alpha)\n",
        "  lasso.fit(X_train, y_train)\n",
        "\n",
        "  # print r-squared score for training data\n",
        "  train_pred = lasso.predict(X_train)\n",
        "  train_r2 = r2_score(y_train, train_pred)\n",
        "  print('Train, r2 for alpha=', alpha, ': ', train_r2)\n",
        "\n",
        "  # print r-squared score for testing data\n",
        "  test_pred = lasso.predict(X_test)\n",
        "  test_r2 = r2_score(y_test, test_pred)\n",
        "  print('Test, r2 for alpha=', alpha, ':', test_r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSkAg6x1QvZN",
        "outputId": "67ff723e-dd91-4df4-eb52-1a66f18e85f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train R2: 0.5088332170910203\n",
            "Test R2: 0.4808847437947158\n",
            "\n",
            "Train, r2 for alpha= 0 :  0.5088332170910204\n",
            "Test, r2 for alpha= 0 : 0.4808847437947159\n",
            "\n",
            "Train, r2 for alpha= 0.0001 :  0.5086112277533077\n",
            "Test, r2 for alpha= 0.0001 : 0.48484175714162425\n",
            "\n",
            "Train, r2 for alpha= 0.1 :  0.45552719460775337\n",
            "Test, r2 for alpha= 0.1 : 0.4998028982681524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-8ca0dedde16e>:29: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  lasso.fit(X_train, y_train)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.222e+00, tolerance: 1.312e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}